"use strict";(self.webpackChunkdocu=self.webpackChunkdocu||[]).push([[31761],{12944:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var a=n(87462),i=(n(67294),n(3905));const r={},o="Langchain",s={unversionedId:"integrations/destinations/langchain",id:"integrations/destinations/langchain",title:"Langchain",description:"Overview",source:"@site/../docs/integrations/destinations/langchain.md",sourceDirName:"integrations/destinations",slug:"/integrations/destinations/langchain",permalink:"/integrations/destinations/langchain",draft:!1,editUrl:"https://github.com/airbytehq/airbyte/blob/master/docs/../docs/integrations/destinations/langchain.md",tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"KVDB",permalink:"/integrations/destinations/kvdb"},next:{title:"Local JSON",permalink:"/integrations/destinations/local-json"}},l={},d=[{value:"Overview",id:"overview",level:2},{value:"Processing",id:"processing",level:3},{value:"Embedding",id:"embedding",level:3},{value:"Indexing",id:"indexing",level:3},{value:"DocArrayHnswSearch vector store",id:"docarrayhnswsearch-vector-store",level:4},{value:"Pinecone vector store",id:"pinecone-vector-store",level:4},{value:"CHANGELOG",id:"changelog",level:2}],p={toc:d},c="wrapper";function m(e){let{components:t,...n}=e;return(0,i.kt)(c,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"langchain"},"Langchain"),(0,i.kt)("h2",{id:"overview"},"Overview"),(0,i.kt)("p",null,"This destination prepares data to be used by ",(0,i.kt)("a",{parentName:"p",href:"https://langchain.com/"},"Langchain")," to retrieve relevant context for question answering use cases."),(0,i.kt)("p",null,"There are three parts to this:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Processing - split up individual records in chunks so they will fit the context window and decide which fields to use as context and which are supplementary metadata."),(0,i.kt)("li",{parentName:"ul"},"Embedding - convert the text into a vector representation using a pre-trained model (currently only OpenAI ",(0,i.kt)("inlineCode",{parentName:"li"},"text-embedding-ada-002")," is supported)"),(0,i.kt)("li",{parentName:"ul"},"Indexing - store the vectors in a vector database for similarity search")),(0,i.kt)("h3",{id:"processing"},"Processing"),(0,i.kt)("p",null,'Each record will be split into text fields and meta fields as configured in the "Processing" section. All text fields are concatenated into a single string and then split into chunks of configured length. The meta fields are stored as-is along with the embedded text chunks. Please note that meta data fields can only be used for filtering and not for retrieval and have to be of type string, number, boolean (all other values are ignored). Depending on the chosen vector store, additional limitations might apply.'),(0,i.kt)("p",null,"When specifying text fields, you can access nested fields in the record by using dot notation, e.g. ",(0,i.kt)("inlineCode",{parentName:"p"},"user.name")," will access the ",(0,i.kt)("inlineCode",{parentName:"p"},"name")," field in the ",(0,i.kt)("inlineCode",{parentName:"p"},"user")," object. It's also possible to use wildcards to access all fields in an object, e.g. ",(0,i.kt)("inlineCode",{parentName:"p"},"users.*.name")," will access all ",(0,i.kt)("inlineCode",{parentName:"p"},"names")," fields in all entries of the ",(0,i.kt)("inlineCode",{parentName:"p"},"users")," array."),(0,i.kt)("p",null,"The chunk length is measured in tokens produced by the ",(0,i.kt)("inlineCode",{parentName:"p"},"tiktoken")," library. The maximum is 8191 tokens, which is the maximum length supported by the ",(0,i.kt)("inlineCode",{parentName:"p"},"text-embedding-ada-002")," model."),(0,i.kt)("p",null,"The stream name gets added as a metadata field ",(0,i.kt)("inlineCode",{parentName:"p"},"_airbyte_stream")," to each document. If available, the primary key of the record is used to identify the document to avoid duplications when updated versions of records are indexed. It is added as the ",(0,i.kt)("inlineCode",{parentName:"p"},"_natural_id")," metadata field."),(0,i.kt)("h3",{id:"embedding"},"Embedding"),(0,i.kt)("p",null,"THe OpenAI embedding API is used to calculate embeddings - see ",(0,i.kt)("a",{parentName:"p",href:"https://beta.openai.com/docs/api-reference/text-embedding"},"OpenAI API")," for details. To do so, an OpenAI API key is required."),(0,i.kt)("p",null,"This integration will be constrained by the ",(0,i.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/guides/rate-limits/overview"},"speed of the OpenAI embedding API"),"."),(0,i.kt)("p",null,"For testing purposes, it's also possible to use the ",(0,i.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/fake"},"Fake embeddings")," integration. It will generate random embeddings and is suitable to test a data pipeline without incurring embedding costs."),(0,i.kt)("h3",{id:"indexing"},"Indexing"),(0,i.kt)("h4",{id:"docarrayhnswsearch-vector-store"},"DocArrayHnswSearch vector store"),(0,i.kt)("p",null,"For local testing, the ",(0,i.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/docarray_hnsw"},"DocArrayHnswSearch")," is recommended - it stores the vectors in a local file with a sqlite database for metadata. It is not suitable for production use, but it is the easiest to set up for testing and development purposes."),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"destination_path")," has to start with ",(0,i.kt)("inlineCode",{parentName:"p"},"/local"),". Any directory nesting within local will be mapped onto the local mount."),(0,i.kt)("p",null,"By default, the ",(0,i.kt)("inlineCode",{parentName:"p"},"LOCAL_ROOT")," env variable in the ",(0,i.kt)("inlineCode",{parentName:"p"},".env")," file is set ",(0,i.kt)("inlineCode",{parentName:"p"},"/tmp/airbyte_local"),"."),(0,i.kt)("p",null,"The local mount is mounted by Docker onto ",(0,i.kt)("inlineCode",{parentName:"p"},"LOCAL_ROOT"),". This means the ",(0,i.kt)("inlineCode",{parentName:"p"},"/local")," is substituted by ",(0,i.kt)("inlineCode",{parentName:"p"},"/tmp/airbyte_local")," by default."),(0,i.kt)("p",null,"DocArrayHnswSearch does not support incremental sync, so the destination will always do a full refresh sync."),(0,i.kt)("p",null,"To initialize a langchain QA chain based on the indexed data, use the following code (set the openai API key as ",(0,i.kt)("inlineCode",{parentName:"p"},"OPENAI_API_KEY")," env variable):"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from langchain import OpenAI\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\nfrom langchain.vectorstores import DocArrayHnswSearch\nfrom langchain.embeddings import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\nvector_store = DocArrayHnswSearch.from_params(embeddings, "/tmp/airbyte_local/<your configured directory>", 1536)\n\nqa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type="stuff", retriever=vector_store.as_retriever())\n')),(0,i.kt)("admonition",{type:"danger"},(0,i.kt)("p",{parentName:"admonition"},"This destination will delete all existing files in the configured directory on each. Make sure to not use a directory that contains other files.")),(0,i.kt)("admonition",{type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"DocArrayHnswSearch is meant to be used on a local workstation and won't work on Kubernetes."),(0,i.kt)("p",{parentName:"admonition"},"Please make sure that Docker Desktop has access to ",(0,i.kt)("inlineCode",{parentName:"p"},"/tmp")," (and ",(0,i.kt)("inlineCode",{parentName:"p"},"/private"),' on a MacOS, as /tmp has a symlink that points to /private. It will not work otherwise). You allow it with "File sharing" in ',(0,i.kt)("inlineCode",{parentName:"p"},"Settings -> Resources -> File sharing -> add the one or two above folder"),' and hit the "Apply & restart" button.')),(0,i.kt)("h4",{id:"pinecone-vector-store"},"Pinecone vector store"),(0,i.kt)("p",null,"For production use, use the pinecone vector store. Use the Pinecone web UI or API to create a project and an index before running the destination. All streams will be indexed into the same index, the ",(0,i.kt)("inlineCode",{parentName:"p"},"_airbyte_stream")," metadata field is used to distinguish between streams. Overall, the size of the metadata fields is limited to 30KB per document. Both OpenAI and Fake embeddings are produced with 1536 vector dimensions, make sure to configure the index accordingly."),(0,i.kt)("p",null,"To initialize a langchain QA chain based on the indexed data, use the following code (set the open API key and pinecone key and environment as ",(0,i.kt)("inlineCode",{parentName:"p"},"OPENAI_API_KEY"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"PINECONE_KEY")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"PINECONE_ENV")," env variables):"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from langchain import OpenAI\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\nfrom langchain.vectorstores import Pinecone\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pinecone\nimport os\n\nembeddings = OpenAIEmbeddings()\npinecone.init(api_key=os.environ["PINECONE_KEY"], environment=os.environ["PINECONE_ENV"])\nindex = pinecone.Index("<your pinecone index name>")\nvector_store = Pinecone(index, embeddings.embed_query, "text")\n\nqa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type="stuff", retriever=vector_store.as_retriever())\n')),(0,i.kt)("h2",{id:"changelog"},"CHANGELOG"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:"left"},"Version"),(0,i.kt)("th",{parentName:"tr",align:"left"},"Date"),(0,i.kt)("th",{parentName:"tr",align:"left"},"Pull Request"),(0,i.kt)("th",{parentName:"tr",align:"left"},"Subject"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:"left"},"0.0.1"),(0,i.kt)("td",{parentName:"tr",align:"left"},"2023-07-26"),(0,i.kt)("td",{parentName:"tr",align:"left"},(0,i.kt)("a",{parentName:"td",href:"https://github.com/airbytehq/airbyte/pull/26184"},"#26184")),(0,i.kt)("td",{parentName:"tr",align:"left"},"Initial release")))))}m.isMDXComponent=!0},3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>u});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=d(n),h=i,u=c["".concat(l,".").concat(h)]||c[h]||m[h]||r;return n?a.createElement(u,o(o({ref:t},p),{},{components:n})):a.createElement(u,o({ref:t},p))}));function u(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:i,o[1]=s;for(var d=2;d<r;d++)o[d]=n[d];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"}}]);