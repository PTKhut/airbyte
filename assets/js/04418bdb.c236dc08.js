"use strict";(self.webpackChunkdocu=self.webpackChunkdocu||[]).push([[2153],{13067:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>o,toc:()=>c});var n=a(87462),r=(a(67294),a(3905));const i={},s="Acceptance Tests Reference",o={unversionedId:"connector-development/testing-connectors/connector-acceptance-tests-reference",id:"connector-development/testing-connectors/connector-acceptance-tests-reference",title:"Acceptance Tests Reference",description:"To ensure a minimum quality bar, Airbyte runs all connectors against the same set of integration tests. Those tests ensure that each connector adheres to the Airbyte Specification and responds correctly to Airbyte commands when provided valid \\(or invalid\\) inputs.",source:"@site/../docs/connector-development/testing-connectors/connector-acceptance-tests-reference.md",sourceDirName:"connector-development/testing-connectors",slug:"/connector-development/testing-connectors/connector-acceptance-tests-reference",permalink:"/connector-development/testing-connectors/connector-acceptance-tests-reference",draft:!1,editUrl:"https://github.com/airbytehq/airbyte/blob/master/docs/../docs/connector-development/testing-connectors/connector-acceptance-tests-reference.md",tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"Testing Connectors",permalink:"/connector-development/testing-connectors/"},next:{title:"Testing A Custom Registry",permalink:"/connector-development/testing-connectors/testing-a-local-catalog-in-development"}},l={},c=[{value:"Architecture of standard tests",id:"architecture-of-standard-tests",level:2},{value:"Setting up standard acceptance tests for your connector",id:"setting-up-standard-acceptance-tests-for-your-connector",level:2},{value:"(Prefered) Option 1: Run against the production acceptance test image",id:"prefered-option-1-run-against-the-production-acceptance-test-image",level:3},{value:"Option 2: Run against the Airbyte CI test suite",id:"option-2-run-against-the-airbyte-ci-test-suite",level:3},{value:"(Debugging) Option 3: Run against the acceptance tests on your branch",id:"debugging-option-3-run-against-the-acceptance-tests-on-your-branch",level:3},{value:"Dynamically managing inputs &amp; resources used in standard tests",id:"dynamically-managing-inputs--resources-used-in-standard-tests",level:2},{value:"Python",id:"python",level:3},{value:"Test Spec",id:"test-spec",level:2},{value:"Test Connection",id:"test-connection",level:2},{value:"Test Discovery",id:"test-discovery",level:2},{value:"Test Basic Read",id:"test-basic-read",level:2},{value:"Schema format checking",id:"schema-format-checking",level:3},{value:"Example of <code>expected_records.jsonl</code>:",id:"example-of-expected_recordsjsonl",level:3},{value:"Test Full Refresh sync",id:"test-full-refresh-sync",level:2},{value:"TestSequentialReads",id:"testsequentialreads",level:3},{value:"Test Incremental sync",id:"test-incremental-sync",level:2},{value:"TestTwoSequentialReads",id:"testtwosequentialreads",level:3},{value:"TestReadSequentialSlices",id:"testreadsequentialslices",level:3},{value:"TestStateWithAbnormallyLargeValues",id:"teststatewithabnormallylargevalues",level:3},{value:"Strictness level",id:"strictness-level",level:2},{value:"Test enforcements in <code>high</code> test strictness level",id:"test-enforcements-in-high-test-strictness-level",level:3},{value:"All acceptance tests are declared, a <code>bypass_reason</code> is filled if a test can&#39;t run",id:"all-acceptance-tests-are-declared-a-bypass_reason-is-filled-if-a-test-cant-run",level:4},{value:"Basic read: no empty streams are allowed without a <code>bypass_reason</code>",id:"basic-read-no-empty-streams-are-allowed-without-a-bypass_reason",level:4},{value:"Basic read: <code>expect_records</code> must be set",id:"basic-read-expect_records-must-be-set",level:4},{value:"Basic read: no <code>configured_catalog_path</code> can be set",id:"basic-read-no-configured_catalog_path-can-be-set",level:4},{value:"Incremental: <code>future_state</code> must be set",id:"incremental-future_state-must-be-set",level:4},{value:"Caching",id:"caching",level:2},{value:"Breaking Changes and Backwards Compatibility",id:"breaking-changes-and-backwards-compatibility",level:2},{value:"Additional Checks",id:"additional-checks",level:2},{value:"Strictness Level",id:"strictness-level-1",level:3},{value:"Allowed Hosts",id:"allowed-hosts",level:3},{value:"Custom environment variable",id:"custom-environment-variable",level:2}],d={toc:c},p="wrapper";function m(e){let{components:t,...i}=e;return(0,r.kt)(p,(0,n.Z)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"acceptance-tests-reference"},"Acceptance Tests Reference"),(0,r.kt)("p",null,"To ensure a minimum quality bar, Airbyte runs all connectors against the same set of integration tests. Those tests ensure that each connector adheres to the ",(0,r.kt)("a",{parentName:"p",href:"/understanding-airbyte/airbyte-protocol"},"Airbyte Specification")," and responds correctly to Airbyte commands when provided valid ","(","or invalid",")"," inputs."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Note: If you are looking for reference documentation for the deprecated first version of test suites, see")," ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/airbytehq/airbyte/tree/e378d40236b6a34e1c1cb481c8952735ec687d88/docs/contributing-to-airbyte/building-new-connector/legacy-standard-source-tests.md"},(0,r.kt)("em",{parentName:"a"},"Standard Tests ","(","Legacy",")")),(0,r.kt)("em",{parentName:"p"},".")),(0,r.kt)("h2",{id:"architecture-of-standard-tests"},"Architecture of standard tests"),(0,r.kt)("p",null,"The Standard Test Suite runs its tests against the connector's Docker image. It takes as input the configuration file ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-tests-config.yml"),"."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Standard test sequence diagram",src:a(90256).Z,width:"1178",height:"874"})),(0,r.kt)("p",null,"The Standard Test Suite use pytest as a test runner and was built as pytest plugin ",(0,r.kt)("inlineCode",{parentName:"p"},"connector-acceptance-test"),". This plugin adds a new configuration option ",(0,r.kt)("inlineCode",{parentName:"p"},"\u2014acceptance-test-config")," - it should points to the folder with ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-tests-config.yml"),"."),(0,r.kt)("p",null,"Each test suite has a timeout and will fail if the limit is exceeded."),(0,r.kt)("p",null,"See all the test cases, their description, and inputs in ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/airbytehq/airbyte/tree/e378d40236b6a34e1c1cb481c8952735ec687d88/docs/contributing-to-airbyte/building-new-connector/connector-acceptance-tests.md"},"Connector Acceptance Tests"),"."),(0,r.kt)("h2",{id:"setting-up-standard-acceptance-tests-for-your-connector"},"Setting up standard acceptance tests for your connector"),(0,r.kt)("p",null,"Create ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml"),". In most cases, your connector already has this file in its root folder. Here is an example of the minimal ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'connector_image: airbyte/source-some-connector:dev\nacceptance-tests:\n  spec:\n    tests:\n      - spec_path: "some_folder/spec.yaml"\n')),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Note: Not all types of tests work for all connectors, only configure the ones that make sense in your scenario. The ",(0,r.kt)("inlineCode",{parentName:"em"},"spec")," and ",(0,r.kt)("inlineCode",{parentName:"em"},"check")," test suites are universal for all sources and destinations, the other test suites are only applicable to sources, and the ",(0,r.kt)("inlineCode",{parentName:"em"},"incremental")," test suite is only applicable if the source connector supports incremental syncs.")),(0,r.kt)("p",null,"Build your connector image if needed."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},"docker build .\n")),(0,r.kt)("p",null,"And test via one of the two following Options"),(0,r.kt)("h3",{id:"prefered-option-1-run-against-the-production-acceptance-test-image"},"(Prefered) Option 1: Run against the production acceptance test image"),(0,r.kt)("p",null,"From the root of your connector run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"./acceptance-test-docker.sh\n")),(0,r.kt)("p",null,"This will run you local connector image against the same test suite that Airbyte uses in production"),(0,r.kt)("h3",{id:"option-2-run-against-the-airbyte-ci-test-suite"},"Option 2: Run against the Airbyte CI test suite"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pipx install airbyte-ci/connectors/pipelines/\nairbyte-ci connectors --name=<name-of-your-connector></name-of-your-connector> --use-remote-secrets=false test\n")),(0,r.kt)("h3",{id:"debugging-option-3-run-against-the-acceptance-tests-on-your-branch"},"(Debugging) Option 3: Run against the acceptance tests on your branch"),(0,r.kt)("p",null,"This will run the acceptance test suite directly with pytest. Allowing you to set breakpoints and debug your connector locally."),(0,r.kt)("p",null,"The only pre-requisite is that you have ",(0,r.kt)("a",{parentName:"p",href:"https://python-poetry.org/docs/#installation"},"Poetry")," installed."),(0,r.kt)("p",null,"Afterwards you do the following from the root of the ",(0,r.kt)("inlineCode",{parentName:"p"},"airbyte")," repo:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cd airbyte-integrations/bases/connector-acceptance-test/\npoetry install\npoetry run pytest -p connector_acceptance_test.plugin --acceptance-test-config=../../connectors/<your-connector> --pdb\n")),(0,r.kt)("p",null,"See other useful pytest options ",(0,r.kt)("a",{parentName:"p",href:"https://docs.pytest.org/en/stable/usage.html"},"here"),"\nSee a more comprehensive guide in our README ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/bases/connector-acceptance-test/README.md"},"here")),(0,r.kt)("h2",{id:"dynamically-managing-inputs--resources-used-in-standard-tests"},"Dynamically managing inputs & resources used in standard tests"),(0,r.kt)("p",null,"Since the inputs to standard tests are often static, the file-based runner is sufficient for most connectors. However, in some cases, you may need to run pre or post hooks to dynamically create or destroy resources for use in standard tests. For example, if we need to spin up a Redshift cluster to use in the test then tear it down afterwards, we need the ability to run code before and after the tests, as well as customize the Redshift cluster URL we pass to the standard tests. If you have need for this use case, please reach out to us via ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/airbytehq/airbyte"},"Github")," or ",(0,r.kt)("a",{parentName:"p",href:"https://slack.airbyte.io"},"Slack"),". We currently support it for Java & Python, and other languages can be made available upon request."),(0,r.kt)("h3",{id:"python"},"Python"),(0,r.kt)("p",null,"Create pytest yield-fixture with your custom setup/teardown code and place it in ",(0,r.kt)("inlineCode",{parentName:"p"},"integration_tests/acceptance.py"),", Example of fixture that starts a docker container before tests and stops before exit:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'@pytest.fixture(scope="session", autouse=True)\ndef connector_setup():\n    """ This fixture is a placeholder for external resources that acceptance test might require.\n    """\n    client = docker.from_env()\n    container = client.containers.run("your/docker-image", detach=True)\n    yield\n    container.stop()\n')),(0,r.kt)("p",null,"These tests are configurable via ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml"),". Each test has a number of inputs, you can provide multiple sets of inputs which will cause the same to run multiple times - one for each set of inputs."),(0,r.kt)("p",null,"Example of ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'connector_image: string # Docker image to test, for example \'airbyte/source-pokeapi:0.1.0\'\nbase_path: string # Base path for all relative paths, optional, default - ./\ncustom_environment_variables:\n  foo: bar\nacceptance_tests: # Tests configuration\n  spec: # list of the test inputs\n    bypass_reason: "Explain why you skipped this test"\n  connection: # list of the test inputs\n    tests:\n      - config_path: string # set #1 of inputs\n        status: string\n      - config_path: string # set #2 of inputs\n        status: string\n    # discovery:  # skip this test\n  incremental:\n    bypass_reason: "Incremental sync are not supported on this connector"\n')),(0,r.kt)("h2",{id:"test-spec"},"Test Spec"),(0,r.kt)("p",null,"Verify that a ",(0,r.kt)("inlineCode",{parentName:"p"},"spec")," operation issued to the connector returns a valid connector specification.\nAdditional tests are validating the backward compatibility of the current specification compared to the specification of the previous connector version. If no previous connector version is found (by default the test looks for a docker image with the same name but with the ",(0,r.kt)("inlineCode",{parentName:"p"},"latest")," tag), this test is skipped.\nThese backward compatibility tests can be bypassed by changing the value of the ",(0,r.kt)("inlineCode",{parentName:"p"},"backward_compatibility_tests_config.disable_for_version")," input in ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml")," (see below).\nOne more test validates the specification against containing exposed secrets. This means fields that potentially could hold a secret value should be explicitly marked with ",(0,r.kt)("inlineCode",{parentName:"p"},'"airbyte_secret": true'),". If an input field like ",(0,r.kt)("inlineCode",{parentName:"p"},"api_key")," / ",(0,r.kt)("inlineCode",{parentName:"p"},"password")," / ",(0,r.kt)("inlineCode",{parentName:"p"},"client_secret")," / etc. is exposed, the test will fail."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"spec_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/spec.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a YAML or JSON file representing the spec expected to be output by this connector")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"backward_compatibility_tests_config.previous_connector_version")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"latest")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Previous connector version to use for backward compatibility tests (expects a version following semantic versioning).")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"backward_compatibility_tests_config.disable_for_version")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Disable the backward compatibility test for a specific version (expects a version following semantic versioning).")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"10"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")))),(0,r.kt)("h2",{id:"test-connection"},"Test Connection"),(0,r.kt)("p",null,"Verify that a check operation issued to the connector with the input config file returns a successful response."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"status")),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"succeed")," ",(0,r.kt)("inlineCode",{parentName:"td"},"failed")," ",(0,r.kt)("inlineCode",{parentName:"td"},"exception")),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"Indicate if connection check should succeed with provided config")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"30"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")))),(0,r.kt)("h2",{id:"test-discovery"},"Test Discovery"),(0,r.kt)("p",null,"Verifies when a ",(0,r.kt)("inlineCode",{parentName:"p"},"discover")," operation is run on the connector using the given config file, a valid catalog is produced by the connector.\nAdditional tests are validating the backward compatibility of the discovered catalog compared to the catalog of the previous connector version. If no previous connector version is found (by default the test looks for a docker image with the same name but with the ",(0,r.kt)("inlineCode",{parentName:"p"},"latest")," tag), this test is skipped.\nThese backward compatibility tests can be bypassed by changing the value of the ",(0,r.kt)("inlineCode",{parentName:"p"},"backward_compatibility_tests_config.disable_for_version")," input in ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml")," (see below)."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"configured_catalog_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"integration_tests/configured_catalog.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to configured catalog")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"30"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"backward_compatibility_tests_config.previous_connector_version")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"latest")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Previous connector version to use for backward compatibility tests (expects a version following semantic versioning).")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"backward_compatibility_tests_config.disable_for_version")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Disable the backward compatibility test for a specific version (expects a version following semantic versioning).")))),(0,r.kt)("h2",{id:"test-basic-read"},"Test Basic Read"),(0,r.kt)("p",null,"Configuring all streams in the input catalog to full refresh mode verifies that a read operation produces some RECORD messages. Each stream should have some data, if you can't guarantee this for particular streams - add them to the ",(0,r.kt)("inlineCode",{parentName:"p"},"empty_streams")," list.\nSet ",(0,r.kt)("inlineCode",{parentName:"p"},"validate_data_points=True")," if possible. This validation is going to be enabled by default and won't be configurable in future releases."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"configured_catalog_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"integration_tests/configured_catalog.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to configured catalog")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"empty_streams")),(0,r.kt)("td",{parentName:"tr",align:"left"},"array of objects"),(0,r.kt)("td",{parentName:"tr",align:"left"},"[","]"),(0,r.kt)("td",{parentName:"tr",align:"left"},"List of streams that might be empty with a ",(0,r.kt)("inlineCode",{parentName:"td"},"bypass_reason"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"empty_streams[0].name")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"Name of the empty stream")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"empty_streams[0].bypass_reason")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Reason why this stream is empty")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"ignored_fields[stream][0].name")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"Name of the ignored field")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"ignored_fields[stream][0].bypass_reason")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Reason why this field is ignored")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"validate_schema")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"True"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Verify that structure and types of records matches the schema from discovery command")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"fail_on_extra_columns")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"True"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Fail schema validation if undeclared columns are found in records. Only relevant when ",(0,r.kt)("inlineCode",{parentName:"td"},"validate_schema=True"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"validate_data_points")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"False"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Validate that all fields in all streams contained at least one data point")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"5","*","60"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_trace_message_on_failure")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"True"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Ensure that a trace message is emitted when the connector crashes")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_records")),(0,r.kt)("td",{parentName:"tr",align:"left"},"object"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Compare produced records with expected records, see details below")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_records.path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"File with expected records")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_records.bypass_reason")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"Explain why this test is bypassed")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_records.extra_fields")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"False"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Allow output records to have other fields i.e: expected records are a subset")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_records.exact_order")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"False"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Ensure that records produced in exact same order")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"expect_records.extra_records")),(0,r.kt)("td",{parentName:"tr",align:"left"},"boolean"),(0,r.kt)("td",{parentName:"tr",align:"left"},"True"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Allow connector to produce extra records, but still enforce all records from the expected file to be produced")))),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"expect_records")," is a nested configuration, if omitted - the part of the test responsible for record matching will be skipped. Due to the fact that we can't identify records without primary keys, only the following flag combinations are supported:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"extra_fields"),(0,r.kt)("th",{parentName:"tr",align:"left"},"exact_order"),(0,r.kt)("th",{parentName:"tr",align:"left"},"extra_records"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},"x"),(0,r.kt)("td",{parentName:"tr",align:"left"},"x"),(0,r.kt)("td",{parentName:"tr",align:"left"})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"x"),(0,r.kt)("td",{parentName:"tr",align:"left"},"x")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"x"),(0,r.kt)("td",{parentName:"tr",align:"left"})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"x")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"})))),(0,r.kt)("h3",{id:"schema-format-checking"},"Schema format checking"),(0,r.kt)("p",null,"If some field has ",(0,r.kt)("a",{parentName:"p",href:"https://json-schema.org/understanding-json-schema/reference/string.html#format"},"format")," attribute specified on its catalog json schema, Connector Acceptance Testing framework performs checking against format. It support checking of all ",(0,r.kt)("a",{parentName:"p",href:"https://json-schema.org/understanding-json-schema/reference/string.html#built-in-formats"},"builtin")," jsonschema formats for draft 7 specification: email, hostnames, ip addresses, time, date and date-time formats."),(0,r.kt)("p",null,"Note: For date-time we are not checking against compliance against ISO8601 ","(","and RFC3339 as subset of it",")",". Since we are using specified format to set database column type on db normalization stage, value should be compliant to bigquery ",(0,r.kt)("a",{parentName:"p",href:"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#timestamp_type"},"timestamp"),' and SQL "timestamp with timezone" formats.'),(0,r.kt)("h3",{id:"example-of-expected_recordsjsonl"},"Example of ",(0,r.kt)("inlineCode",{parentName:"h3"},"expected_records.jsonl"),":"),(0,r.kt)("p",null,"In general, the expected_records.jsonl should contain the subset of output of the records of particular stream you need to test. The required fields are: ",(0,r.kt)("inlineCode",{parentName:"p"},"stream, data, emitted_at")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'{"stream": "my_stream", "data": {"field_1": "value0", "field_2": "value0", "field_3": null, "field_4": {"is_true": true}, "field_5": 123}, "emitted_at": 1626172757000}\n{"stream": "my_stream", "data": {"field_1": "value1", "field_2": "value1", "field_3": null, "field_4": {"is_true": false}, "field_5": 456}, "emitted_at": 1626172757000}\n{"stream": "my_stream", "data": {"field_1": "value2", "field_2": "value2", "field_3": null, "field_4": {"is_true": true}, "field_5": 678}, "emitted_at": 1626172757000}\n{"stream": "my_stream", "data": {"field_1": "value3", "field_2": "value3", "field_3": null, "field_4": {"is_true": false}, "field_5": 91011}, "emitted_at": 1626172757000}\n')),(0,r.kt)("h2",{id:"test-full-refresh-sync"},"Test Full Refresh sync"),(0,r.kt)("h3",{id:"testsequentialreads"},"TestSequentialReads"),(0,r.kt)("p",null,"This test performs two read operations on all streams which support full refresh syncs. It then verifies that the RECORD messages output from both were identical or the former is a strict subset of the latter."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"configured_catalog_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"integration_tests/configured_catalog.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to configured catalog")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"20","*","60"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"ignored_fields")),(0,r.kt)("td",{parentName:"tr",align:"left"},"dict"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"For each stream, list of fields path ignoring in sequential reads test")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"ignored_fields[stream][0].name")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"}),(0,r.kt)("td",{parentName:"tr",align:"left"},"Name of the ignored field")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"ignored_fields[stream][0].bypass_reason")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Reason why this field is ignored")))),(0,r.kt)("h2",{id:"test-incremental-sync"},"Test Incremental sync"),(0,r.kt)("h3",{id:"testtwosequentialreads"},"TestTwoSequentialReads"),(0,r.kt)("p",null,"This test verifies that all streams in the input catalog which support incremental sync can do so correctly. It does this by running two read operations: the first takes the configured catalog and config provided to this test as input. It then verifies that the sync produced a non-zero number of ",(0,r.kt)("inlineCode",{parentName:"p"},"RECORD")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," messages. The second read takes the same catalog and config used in the first test, plus the last ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," message output by the first read operation as the input state file. It verifies that either no records are produced ","(","since we read all records in the first sync",")"," or all records that produced have cursor value greater or equal to cursor value from ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," message. This test is performed only for streams that support incremental. Streams that do not support incremental sync are ignored. If no streams in the input catalog support incremental sync, this test is skipped."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"configured_catalog_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"integration_tests/configured_catalog.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to configured catalog")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"cursor_paths")),(0,r.kt)("td",{parentName:"tr",align:"left"},"dict"),(0,r.kt)("td",{parentName:"tr",align:"left"},"{}"),(0,r.kt)("td",{parentName:"tr",align:"left"},"For each stream, the path of its cursor field in the output state messages. If omitted the path will be taken from the last piece of path from stream cursor_field.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"20","*","60"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"threshold_days")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"0"),(0,r.kt)("td",{parentName:"tr",align:"left"},"For date-based cursors, allow records to be emitted with a cursor value this number of days before the state value.")))),(0,r.kt)("h3",{id:"testreadsequentialslices"},"TestReadSequentialSlices"),(0,r.kt)("p",null,"This test offers more comprehensive verification that all streams in the input catalog which support incremental syncs perform the sync correctly. It does so in two phases. The first phase uses the configured catalog and config provided to this test as input to make a request to the partner API and assemble the complete set of messages to be synced. It then verifies that the sync produced a non-zero number of ",(0,r.kt)("inlineCode",{parentName:"p"},"RECORD")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," messages. This set of messages is partitioned into batches of a ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," message followed by zero or more ",(0,r.kt)("inlineCode",{parentName:"p"},"RECORD")," messages. For each batch of messages, the initial ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," message is used as input for a read operation to get records with respect to the cursor. The test then verifies that all of the ",(0,r.kt)("inlineCode",{parentName:"p"},"RECORDS")," retrieved have a cursor value greater or equal to the cursor from the current ",(0,r.kt)("inlineCode",{parentName:"p"},"STATE")," message. This test is performed only for streams that support incremental. Streams that do not support incremental sync are ignored. If no streams in the input catalog support incremental sync, this test is skipped."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"configured_catalog_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"integration_tests/configured_catalog.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to configured catalog")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"cursor_paths")),(0,r.kt)("td",{parentName:"tr",align:"left"},"dict"),(0,r.kt)("td",{parentName:"tr",align:"left"},"{}"),(0,r.kt)("td",{parentName:"tr",align:"left"},"For each stream, the path of its cursor field in the output state messages. If omitted the path will be taken from the last piece of path from stream cursor_field.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"20","*","60"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"threshold_days")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"0"),(0,r.kt)("td",{parentName:"tr",align:"left"},"For date-based cursors, allow records to be emitted with a cursor value this number of days before the state value.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"skip_comprehensive_incremental_tests")),(0,r.kt)("td",{parentName:"tr",align:"left"},"bool"),(0,r.kt)("td",{parentName:"tr",align:"left"},"false"),(0,r.kt)("td",{parentName:"tr",align:"left"},"For non-GA and in-development connectors, control whether the more comprehensive incremental tests will be skipped")))),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note that this test samples a fraction of stream slices across an incremental sync in order to reduce test duration and avoid spamming partner APIs")),(0,r.kt)("h3",{id:"teststatewithabnormallylargevalues"},"TestStateWithAbnormallyLargeValues"),(0,r.kt)("p",null,"This test verifies that sync produces no records when run with the STATE with abnormally large values"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Input"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Type"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Note"),(0,r.kt)("th",{parentName:"tr",align:"left"}))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"config_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"secrets/config.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to a JSON object representing a valid connector configuration"),(0,r.kt)("td",{parentName:"tr",align:"left"})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"configured_catalog_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"integration_tests/configured_catalog.json")),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to configured catalog"),(0,r.kt)("td",{parentName:"tr",align:"left"})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"future_state_path")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Path to the state file with abnormally large cursor values"),(0,r.kt)("td",{parentName:"tr",align:"left"})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"timeout_seconds")),(0,r.kt)("td",{parentName:"tr",align:"left"},"int"),(0,r.kt)("td",{parentName:"tr",align:"left"},"20","*","60"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Test execution timeout in seconds"),(0,r.kt)("td",{parentName:"tr",align:"left"})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("inlineCode",{parentName:"td"},"bypass_reason")),(0,r.kt)("td",{parentName:"tr",align:"left"},"string"),(0,r.kt)("td",{parentName:"tr",align:"left"},"None"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Explain why this test is bypassed"),(0,r.kt)("td",{parentName:"tr",align:"left"})))),(0,r.kt)("h2",{id:"strictness-level"},"Strictness level"),(0,r.kt)("p",null,"To enforce maximal coverage of acceptances tests we expose a ",(0,r.kt)("inlineCode",{parentName:"p"},"test_strictness_level")," field at the root of the ",(0,r.kt)("inlineCode",{parentName:"p"},"acceptance-test-config.yml")," configuration.\nThe default ",(0,r.kt)("inlineCode",{parentName:"p"},"test_strictness_level")," is ",(0,r.kt)("inlineCode",{parentName:"p"},"low"),", but for generally available connectors it is expected to be eventually set to ",(0,r.kt)("inlineCode",{parentName:"p"},"high"),"."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Note: For now, the strictness level can only be applied for sources, not for destination connectors")),(0,r.kt)("h3",{id:"test-enforcements-in-high-test-strictness-level"},"Test enforcements in ",(0,r.kt)("inlineCode",{parentName:"h3"},"high")," test strictness level"),(0,r.kt)("h4",{id:"all-acceptance-tests-are-declared-a-bypass_reason-is-filled-if-a-test-cant-run"},"All acceptance tests are declared, a ",(0,r.kt)("inlineCode",{parentName:"h4"},"bypass_reason")," is filled if a test can't run"),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"high")," test strictness level we expect all acceptance tests to be declared:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"spec")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"connection")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"discovery")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"basic_read")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"full_refresh")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"incremental"))),(0,r.kt)("p",null,"If a test can't be run for a valid technical or organizational reason a ",(0,r.kt)("inlineCode",{parentName:"p"},"bypass_reason")," can be declared to skip this test.\nE.G. ",(0,r.kt)("inlineCode",{parentName:"p"},"source-pokeapi")," does not support incremental syncs, we can skip this test when ",(0,r.kt)("inlineCode",{parentName:"p"},"test_strictness_level")," is ",(0,r.kt)("inlineCode",{parentName:"p"},"high")," by setting a ",(0,r.kt)("inlineCode",{parentName:"p"},"bypass_reason")," under ",(0,r.kt)("inlineCode",{parentName:"p"},"incremental"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'connector_image: "airbyte/source-pokeapi"\ntest_strictness_level: high\nacceptance_tests:\n  spec:\n    tests:\n      - spec_path: "source_pokeapi/spec.json"\n  connection:\n    tests:\n      - config_path: "integration_tests/config.json"\n        status: "succeed"\n  discovery:\n    tests:\n      - config_path: "integration_tests/config.json"\n  basic_read:\n    tests:\n      - config_path: "integration_tests/config.json"\n  full_refresh:\n    tests:\n      - config_path: "integration_tests/config.json"\n        configured_catalog_path: "integration_tests/configured_catalog.json"\n  incremental:\n    bypass_reason: "Incremental syncs are not supported on this connector."\n')),(0,r.kt)("h4",{id:"basic-read-no-empty-streams-are-allowed-without-a-bypass_reason"},"Basic read: no empty streams are allowed without a ",(0,r.kt)("inlineCode",{parentName:"h4"},"bypass_reason")),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"high")," test strictness level we expect that all streams declared in ",(0,r.kt)("inlineCode",{parentName:"p"},"empty-streams")," to have a ",(0,r.kt)("inlineCode",{parentName:"p"},"bypass_reason")," filled in."),(0,r.kt)("p",null,"E.G. Two streams from ",(0,r.kt)("inlineCode",{parentName:"p"},"source-recharge")," can't be seeded with test data, they are declared as ",(0,r.kt)("inlineCode",{parentName:"p"},"empty_stream")," we an explicit bypass reason."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'connector_image: airbyte/source-recharge:dev\ntest_strictness_level: high\nacceptance_tests:\n  basic_read:\n    tests:\n      - config_path: secrets/config.json\n        empty_streams:\n          - name: collections\n            bypass_reason: "This stream can\'t be seeded in our sandbox account"\n          - name: discounts\n            bypass_reason: "This stream can\'t be seeded in our sandbox account"\n        timeout_seconds: 1200\n')),(0,r.kt)("h4",{id:"basic-read-expect_records-must-be-set"},"Basic read: ",(0,r.kt)("inlineCode",{parentName:"h4"},"expect_records")," must be set"),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"high")," test strictness level we expect the ",(0,r.kt)("inlineCode",{parentName:"p"},"expect_records")," subtest to be set.\nIf you can't create an ",(0,r.kt)("inlineCode",{parentName:"p"},"expected_records.jsonl")," with all the existing stream you need to declare the missing streams in the ",(0,r.kt)("inlineCode",{parentName:"p"},"empty_streams")," section.\nIf you can't get an ",(0,r.kt)("inlineCode",{parentName:"p"},"expected_records.jsonl")," file at all, you must fill in a ",(0,r.kt)("inlineCode",{parentName:"p"},"bypass_reason"),"."),(0,r.kt)("h4",{id:"basic-read-no-configured_catalog_path-can-be-set"},"Basic read: no ",(0,r.kt)("inlineCode",{parentName:"h4"},"configured_catalog_path")," can be set"),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"high")," test strictness level we want to run the ",(0,r.kt)("inlineCode",{parentName:"p"},"basic_read")," test on a configured catalog created from the discovered catalog from which we remove declared empty streams. Declaring ",(0,r.kt)("inlineCode",{parentName:"p"},"configured_catalog_path")," in the test configuration is not allowed."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'connector_image: airbyte/source-recharge:dev\ntest_strictness_level: high\nacceptance_tests:\n  basic_read:\n    tests:\n      - config_path: secrets/config.json\n        empty_streams:\n          - name: collections\n            bypass_reason: "This stream can\'t be seeded in our sandbox account"\n          - name: discounts\n            bypass_reason: "This stream can\'t be seeded in our sandbox account"\n        timeout_seconds: 1200\n')),(0,r.kt)("h4",{id:"incremental-future_state-must-be-set"},"Incremental: ",(0,r.kt)("inlineCode",{parentName:"h4"},"future_state")," must be set"),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"high")," test strictness level we expect the ",(0,r.kt)("inlineCode",{parentName:"p"},"future_state")," configuration to be set.\nThe future state JSON file (usually ",(0,r.kt)("inlineCode",{parentName:"p"},"abnormal_states.json"),") must contain one state for each stream declared in the configured catalog.\n",(0,r.kt)("inlineCode",{parentName:"p"},"missing_streams")," can be set to ignore a subset of the streams with a valid bypass reason. E.G:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'test_strictness_level: high\nconnector_image: airbyte/source-my-connector:dev\nacceptance_tests:\n  ...\n  incremental:\n    tests:\n      - config_path: secrets/config.json\n        configured_catalog_path: integration_tests/configured_catalog.json\n        cursor_paths:\n          ...\n        future_state:\n          future_state_path: integration_tests/abnormal_state.json\n          missing_streams:\n            - name: my_missing_stream\n              bypass_reason: "Please fill a good reason"\n')),(0,r.kt)("h2",{id:"caching"},"Caching"),(0,r.kt)("p",null,"We cache discovered catalogs by default for performance and reuse the same discovered catalog through all tests.\nYou can disable this behavior by setting ",(0,r.kt)("inlineCode",{parentName:"p"},"cached_discovered_catalog: False")," at the root of the configuration."),(0,r.kt)("h2",{id:"breaking-changes-and-backwards-compatibility"},"Breaking Changes and Backwards Compatibility"),(0,r.kt)("p",null,"Breaking changes are modifications that make previous versions of the connector incompatible, requiring a major version bump. Here are the various types of changes that we consider breaking:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Changes to Stream Schema")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Removing a Field"),": If a field is removed from the stream's schema, it's a breaking change. Clients expecting the field may fail when it's absent."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Changing Field Type"),": If the data type of a field is changed, it could break clients expecting the original type. For instance, changing a field from string to integer would be a breaking change."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Renaming a Field"),": If a field is renamed, it can break existing clients that expect the field by its original name."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Changes to Stream Behaviour")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Changing the Cursor"),": Changing the cursor field for incremental streams can cause data discrepancies or synchronization issues. Therefore, it's considered a breaking change."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Renaming a Stream"),": If a stream is renamed, it could cause failures for clients expecting the stream with its original name. Hence, this is a breaking change."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Changing Sync Mechanism"),": If a stream's sync mechanism changes, such as switching from full refresh sync to incremental sync (or vice versa), it's a breaking change. Existing workflows may fail or behave unexpectedly due to this change."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Changes to Configuration Options")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Removing or Renaming Options"),": If configuration options are removed or renamed, it could break clients using those options, hence, is considered a breaking change."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Changing Default Values or Behaviours"),": Altering default values or behaviours of configuration options can break existing clients that rely on previous defaults."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Changes to Authentication Mechanism")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Any change to the connector's authentication mechanism that isn't backwards compatible is a breaking change. For example, switching from API key authentication to OAuth without supporting both is a breaking change."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Changes to Error Handling")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Altering the way errors are handled can be a breaking change. For example, if a certain type of error was previously ignored and now causes the connector to fail, it could break user's existing workflows."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Changes That Require User Intervention")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"If a change requires user intervention, such as manually updating settings or reconfiguring workflows, it would be considered a breaking change.")))),(0,r.kt)("p",null,"Please note that this is an exhaustive but not an exclusive list. Other changes could be considered breaking if they disrupt the functionality of the connector or alter user expectations in a significant way."),(0,r.kt)("h2",{id:"additional-checks"},"Additional Checks"),(0,r.kt)("p",null,"While not necessarily related to Connector Acceptance Testing, Airbyte employs a number of additional checks which run on connector Pull Requests which check the following items:"),(0,r.kt)("h3",{id:"strictness-level-1"},"Strictness Level"),(0,r.kt)("p",null,"Generally Available Connectors must enable high-strictness testing for the Connector Acceptance Test suite. This ensures that these connectors have implemented the most robust collection of tests."),(0,r.kt)("h3",{id:"allowed-hosts"},"Allowed Hosts"),(0,r.kt)("p",null,"GA and Beta connectors are required to provide an entry for Allowed Hosts in the ",(0,r.kt)("a",{parentName:"p",href:"/connector-development/connector-metadata-file"},"metadata.yaml")," for the connector. You can provide:"),(0,r.kt)("p",null,"A list of static hostnames or IP addresses. Wildcards are valid."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'data:\n  # ...\n  allowedHosts:\n    hosts:\n      - "api.github.com"\n      - "*.hubspot.com"\n')),(0,r.kt)("p",null,"A list of dynamic hostnames or IP addresses which reference values from the connector's configuration. The variable names need to match the connector's config exactly. In this example, ",(0,r.kt)("inlineCode",{parentName:"p"},"subdomain")," is a required option defined by the connector's SPEC response. It is also possible to refrence sub-fields with dot-notation, e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"networking_options.tunnel_host"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'data:\n  # ...\n  allowedHosts:\n    hosts:\n      - "${subdomain}.vendor.com"\n      - "${networking_options.tunnel_host}"\n')),(0,r.kt)("p",null,"or prevent network access for this connector entirely"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"data:\n  # ...\n  allowedHosts:\n    hosts: []\n")),(0,r.kt)("h2",{id:"custom-environment-variable"},"Custom environment variable"),(0,r.kt)("p",null,"The connector under tests can be run with custom environment variables:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'connector_image: "airbyte/source-pokeapi"\ncustom_environment_variables:\n  my_custom_environment_variable: value\n...\n')))}m.isMDXComponent=!0},3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>u});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),p=c(a),g=r,u=p["".concat(l,".").concat(g)]||p[g]||m[g]||i;return a?n.createElement(u,s(s({ref:t},d),{},{components:a})):n.createElement(u,s({ref:t},d))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,s=new Array(i);s[0]=g;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[p]="string"==typeof e?e:r,s[1]=o;for(var c=2;c<i;c++)s[c]=a[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},90256:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/standard_tests_sequence_diagram-e16dc2dfe682e24b9d530650345ce7e2.png"}}]);