"use strict";(self.webpackChunkdocu=self.webpackChunkdocu||[]).push([[84572],{99979:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var r=n(87462),i=(n(67294),n(3905));const o={},a="Developing on Docker",l={unversionedId:"contributing-to-airbyte/resources/developing-on-docker",id:"contributing-to-airbyte/resources/developing-on-docker",title:"Developing on Docker",description:"Incrementality",source:"@site/../docs/contributing-to-airbyte/resources/developing-on-docker.md",sourceDirName:"contributing-to-airbyte/resources",slug:"/contributing-to-airbyte/resources/developing-on-docker",permalink:"/contributing-to-airbyte/resources/developing-on-docker",draft:!1,editUrl:"https://github.com/airbytehq/airbyte/blob/master/docs/../docs/contributing-to-airbyte/resources/developing-on-docker.md",tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"Developing Locally",permalink:"/contributing-to-airbyte/resources/developing-locally"},next:{title:"Gradle Cheatsheet",permalink:"/contributing-to-airbyte/resources/gradle"}},s={},d=[{value:"Incrementality",id:"incrementality",level:2},{value:"Adding a new docker build",id:"adding-a-new-docker-build",level:2},{value:"Building the docker images",id:"building-the-docker-images",level:2},{value:"Handling the OSS version",id:"handling-the-oss-version",level:2},{value:"Existing modules",id:"existing-modules",level:3},{value:"New module",id:"new-module",level:3}],c={toc:d},p="wrapper";function u(e){let{components:t,...n}=e;return(0,i.kt)(p,(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"developing-on-docker"},"Developing on Docker"),(0,i.kt)("h2",{id:"incrementality"},"Incrementality"),(0,i.kt)("p",null,"The docker build is fully incremental for the platform build, which means that it will only build an image if it is needed. We need to keep it that\nway.\nThe top level ",(0,i.kt)("inlineCode",{parentName:"p"},"build.gradle")," file defines several convenient tasks for building a docker image.\n1) The ",(0,i.kt)("inlineCode",{parentName:"p"},"copyGeneratedTar")," task copies a generated TAR file from a default location into the default location used by the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/bmuschko/gradle-docker-plugin"},"docker plugin"),".\n2) The ",(0,i.kt)("inlineCode",{parentName:"p"},"buildDockerImage")," task is a convenience class for configuring the above linked docker plugin that centralizes configuration logic commonly found in our dockerfiles.\n3) Makes the ",(0,i.kt)("inlineCode",{parentName:"p"},"buildDockerImage")," task depend on the Gradle ",(0,i.kt)("inlineCode",{parentName:"p"},"assemble")," task."),(0,i.kt)("p",null,"These tasks are created in a subproject if the subproject has a ",(0,i.kt)("inlineCode",{parentName:"p"},"gradle.properties")," file with the ",(0,i.kt)("inlineCode",{parentName:"p"},"dockerImageName")," property. This property sets the built docker image's name."),(0,i.kt)("h2",{id:"adding-a-new-docker-build"},"Adding a new docker build"),(0,i.kt)("p",null,"Once you have a ",(0,i.kt)("inlineCode",{parentName:"p"},"Dockerfile"),", generating the docker image is done in the following way:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Create a ",(0,i.kt)("inlineCode",{parentName:"li"},"gradle.properties")," file in the subproject with the ",(0,i.kt)("inlineCode",{parentName:"li"},"dockerImageName")," property set to the docker image name.")),(0,i.kt)("p",null,"For example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-groovy"},"// In the gradle.properties file.\ndockerImageName=cron\n")),(0,i.kt)("ol",{start:2},(0,i.kt)("li",{parentName:"ol"},"If this is a subproject producing a TAR, take advantage of the pre-provided task by configuring the build docker task to\ndepend on the copy TAR task in the subproject's build.gradle.")),(0,i.kt)("p",null,"For example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-groovy"},'tasks.named("buildDockerImage") {\n    dependsOn copyGeneratedTar\n}\n')),(0,i.kt)("ol",{start:3},(0,i.kt)("li",{parentName:"ol"},"If this is a subproject with a more custom copy strategy, define your own task to copy the necessary files and configure\nthe build docker task to depend on this custom copy task in the subproject's build.gradle.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-groovy"},"task copyScripts(type: Copy) {\n    dependsOn copyDocker\n    from('scripts')\n    into 'build/docker/bin/scripts'\n}\n\ntasks.named(\"buildDockerImage\") {\n    dependsOn copyScripts\n}\n")),(0,i.kt)("h2",{id:"building-the-docker-images"},"Building the docker images"),(0,i.kt)("p",null,"The gradle task ",(0,i.kt)("inlineCode",{parentName:"p"},"generate-docker")," allows to build all the docker images."),(0,i.kt)("h2",{id:"handling-the-oss-version"},"Handling the OSS version"),(0,i.kt)("p",null,"The docker images that are running using a jar need to the latest published OSS version on master. Here is how it is handle:"),(0,i.kt)("h3",{id:"existing-modules"},"Existing modules"),(0,i.kt)("p",null,"The version should already be present. If a new version is published while a PR is open, it should generate a conflict, that will prevent you from\nmerging the review. There are scenarios where it is going to generate and error (The Dockerfile is moved for example), the way to avoid any issue\nis to:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Check the ",(0,i.kt)("inlineCode",{parentName:"li"},".env")," file to make sure that the latest version align with the version in the PR"),(0,i.kt)("li",{parentName:"ul"},"Merge the ",(0,i.kt)("inlineCode",{parentName:"li"},"master")," branch in the PR and make sure that the build is working right before merging.")),(0,i.kt)("p",null,"If the version don't align, it will break the remote ",(0,i.kt)("inlineCode",{parentName:"p"},"master")," build."),(0,i.kt)("p",null,"The version will be automatically replace with new version when releasing the OSS version using the ",(0,i.kt)("inlineCode",{parentName:"p"},".bumpversion.cfg"),"."),(0,i.kt)("h3",{id:"new-module"},"New module"),(0,i.kt)("p",null,"This is trickier than handling the version of an existing module.\nFirst your docker file generating an image need to be added to the ",(0,i.kt)("inlineCode",{parentName:"p"},".bumpversion.cfg"),". For each and every version you want to build with, the\ndocker image will need to be manually tag and push until the PR is merge. The reason is that the build has a check to know if all the potential\ndocker images are present in the docker repository. It is done the following way:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"docker tag 7d94ea2ad657 airbyte/temporal:0.30.35-alpha\ndocker push airbyte/temporal:0.30.35-alpha\n")),(0,i.kt)("p",null,"The image ID can be retrieved using ",(0,i.kt)("inlineCode",{parentName:"p"},"docker images")," or the docker desktop UI."))}u.isMDXComponent=!0},3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var r=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=r.createContext({}),d=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},c=function(e){var t=d(e.components);return r.createElement(s.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},g=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=d(n),g=i,m=p["".concat(s,".").concat(g)]||p[g]||u[g]||o;return n?r.createElement(m,a(a({ref:t},c),{},{components:n})):r.createElement(m,a({ref:t},c))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,a=new Array(o);a[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:i,a[1]=l;for(var d=2;d<o;d++)a[d]=n[d];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}g.displayName="MDXCreateElement"}}]);